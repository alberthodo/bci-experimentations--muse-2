SPOTIFY BCI CONTROL SYSTEM - DEVELOPMENT PLAN
==================================================

PROJECT OVERVIEW:
Brain-Computer Interface system using Muse headset to control Spotify playback through mental gestures and physiological signals.

CORE DIFFERENCES FROM PROJECT 1:
- No WebSocket communication (direct local control)
- PPG data integration for jaw clench detection
- Spotify API integration
- Real-time audio/visual feedback system
- State machine for command execution

==================================================
PHASE 1: SYSTEM ARCHITECTURE & SETUP
==================================================

1.1 HARDWARE REQUIREMENTS:
- Muse 2 or Muse S headband (EEG + PPG sensors)
- Computer with Bluetooth capability
- Spotify Premium account (required for API control)
- Audio output device for feedback sounds

1.2 SOFTWARE DEPENDENCIES:
- brainflow (Muse connection and data streaming)
- spotipy (Spotify Web API Python library)
- numpy, scipy (signal processing)
- pygame or playsound (audio feedback)
- tkinter (simple GUI for visual feedback)
- requests (API calls)

1.3 SPOTIFY API SETUP:
- Register app at https://developer.spotify.com/dashboard
- Obtain Client ID and Client Secret
- Required scopes: user-read-playback-state, user-modify-playback-state
- Set up OAuth2 authentication flow
- Test API connection and device detection

==================================================
PHASE 2: SIGNAL PROCESSING ARCHITECTURE
==================================================

2.1 DATA ACQUISITION MODULE (muse_connector2.py):
- Connect to Muse device via Brainflow
- Stream both EEG and PPG data simultaneously
- Real-time data buffering (separate buffers for EEG/PPG)
- Data rate: 256 Hz for EEG, 64 Hz for PPG
- Channel mapping: EEG (AF7, AF8, TP9, TP10), PPG (AUX channels)

2.2 SIGNAL PROCESSING MODULES:

A) EEG Processor (eeg_processor.py):
   - Bandpass filtering (0.5-50 Hz)
   - Notch filtering (50/60 Hz)
   - Power spectral density calculation
   - Alpha band (8-13 Hz) and Beta band (13-30 Hz) power extraction
   - Real-time mental state classification (Focus vs Relaxation)

B) PPG Processor (ppg_processor.py):
   - High-pass filtering (0.1 Hz) to remove DC component
   - Peak detection algorithm for physiological events
   - Double-blink detection (two peaks within 300-500ms)
   - Jaw clench detection (sustained elevated signal >1 second)
   - False positive filtering

C) Blink Detector Enhanced (blink_detector2.py):
   - Combine EEG frontal channels (AF7, AF8) and PPG data
   - Multi-modal blink detection for higher accuracy
   - Voluntary vs involuntary blink classification
   - Adaptive thresholding based on baseline activity

==================================================
PHASE 3: CONTROL COMMAND MAPPING
==================================================

3.1 GESTURE-TO-ACTION MAPPING:

| User Gesture          | Detection Method           | Spotify Action    | Cooldown |
|-----------------------|----------------------------|-------------------|----------|
| Double-Blink         | PPG + EEG peaks           | Play/Pause Toggle | 1.0s     |
| Jaw Clench           | Sustained PPG elevation    | Next Track        | 1.5s     |
| Sustained Focus      | Beta > Alpha for >2s       | Volume Up         | 0.5s     |
| Sustained Relaxation | Alpha > Beta for >2s       | Volume Down       | 0.5s     |

3.2 SIGNAL THRESHOLDS (Initial Values - To Be Tuned):
- Double-blink: Two PPG peaks >150μV within 300-500ms
- Jaw clench: PPG amplitude >200μV sustained for >1.0s
- Focus state: Beta/Alpha ratio >1.2 for >2.0s
- Relaxation state: Alpha/Beta ratio >1.2 for >2.0s

3.3 STATE MACHINE LOGIC:
- IDLE: Waiting for gesture detection
- COMMAND_DETECTED: Gesture recognized, executing action
- COOLDOWN: Preventing double-triggers
- SUSTAINED_ACTION: Ongoing volume control
- ERROR: Handle API failures gracefully

==================================================
PHASE 4: SPOTIFY INTEGRATION MODULE
==================================================

4.1 SPOTIFY CONTROLLER (spotify_controller.py):
- OAuth2 authentication setup
- Device discovery and selection
- Playback state monitoring
- Command execution methods:
  * play_pause_toggle()
  * next_track()
  * volume_up(step=5)
  * volume_down(step=5)
  * get_current_playback()

4.2 API ERROR HANDLING:
- Network connectivity issues
- Spotify app not running
- No active device found
- Rate limiting (API calls per minute)
- Token refresh mechanism

4.3 FALLBACK MECHANISMS:
- Local audio feedback when Spotify unavailable
- Command queuing during temporary disconnections
- Graceful degradation of functionality

==================================================
PHASE 5: FEEDBACK SYSTEM
==================================================

5.1 AUDIO FEEDBACK (audio_feedback.py):
- Sound library: pygame.mixer for low-latency playback
- Feedback sounds:
  * Play: Gentle ascending chime (200ms)
  * Pause: Gentle descending chime (200ms)
  * Next Track: Quick tap sound (100ms)
  * Volume Change: Soft tick (50ms)
  * Error: Low warning tone (300ms)

5.2 VISUAL FEEDBACK GUI (gui_feedback.py):
- Tkinter-based simple interface
- Real-time display elements:
  * Connection status indicator (Green/Red)
  * Last command executed with timestamp
  * Current volume level (large, easy-to-read)
  * Mental state indicator (Focus/Relaxed/Neutral)
  * Signal quality meters for EEG/PPG

5.3 LOGGING SYSTEM:
- Command execution log with timestamps
- Signal quality metrics
- Error tracking and debugging info
- User session statistics

==================================================
PHASE 6: MAIN APPLICATION STRUCTURE
==================================================

6.1 MAIN APPLICATION (main2.py):
```
INITIALIZATION:
1. Initialize Muse connection
2. Setup Spotify authentication
3. Start GUI feedback window
4. Initialize audio feedback system
5. Create signal processing pipeline

MAIN LOOP:
1. Acquire EEG/PPG data (non-blocking)
2. Process signals in parallel
3. Detect gestures/mental states
4. Execute commands via state machine
5. Provide immediate feedback
6. Update GUI display
7. Handle errors gracefully

CLEANUP:
1. Stop data streaming
2. Close Spotify connection
3. Save session logs
4. Disconnect from Muse
```

6.2 MODULAR ARCHITECTURE:
```
main2.py                 # Main orchestration
├── muse_connector2.py   # Hardware interface
├── eeg_processor.py     # EEG signal processing
├── ppg_processor.py     # PPG signal processing
├── blink_detector2.py   # Enhanced blink detection
├── spotify_controller.py # Spotify API interface
├── audio_feedback.py    # Sound feedback system
├── gui_feedback.py      # Visual interface
├── command_processor.py # State machine & gesture mapping
└── config.py           # Configuration settings
```

==================================================
PHASE 7: DEVELOPMENT MILESTONES
==================================================

MILESTONE 1: Basic Data Acquisition
- [ ] Muse connection with EEG + PPG streaming
- [ ] Real-time data visualization
- [ ] Signal quality assessment

MILESTONE 2: Signal Processing Pipeline
- [ ] EEG processing (Alpha/Beta detection)
- [ ] PPG processing (peak detection)
- [ ] Enhanced blink detection
- [ ] Basic gesture recognition

MILESTONE 3: Spotify Integration
- [ ] OAuth2 authentication setup
- [ ] Basic playback control (play/pause/next)
- [ ] Volume control implementation
- [ ] Error handling and reconnection

MILESTONE 4: Command Mapping & State Machine
- [ ] Gesture-to-command mapping
- [ ] State machine implementation
- [ ] Cooldown and false positive prevention
- [ ] Command execution reliability

MILESTONE 5: Feedback Systems
- [ ] Audio feedback implementation
- [ ] GUI development and real-time updates
- [ ] User experience optimization
- [ ] Session logging and statistics

MILESTONE 6: Integration & Testing
- [ ] Full system integration
- [ ] User testing and threshold tuning
- [ ] Performance optimization
- [ ] Documentation and user guide

==================================================
PHASE 8: CONFIGURATION & TUNING
==================================================

8.1 USER CALIBRATION PROCESS:
- 2-minute baseline recording for personalized thresholds
- Gesture training mode for optimal detection
- Individual sensitivity adjustments
- Save user profiles for consistent experience

8.2 ADAPTIVE ALGORITHMS:
- Dynamic threshold adjustment based on session data
- Learning from false positives/negatives
- Signal quality-based parameter scaling
- Fatigue detection and compensation

8.3 PERFORMANCE OPTIMIZATION:
- Real-time processing requirements (<100ms latency)
- Memory usage optimization for long sessions
- CPU usage monitoring and load balancing
- Battery life considerations for extended use

==================================================
TECHNICAL CONSIDERATIONS
==================================================

1. REAL-TIME CONSTRAINTS:
   - Maximum latency: 200ms from gesture to feedback
   - Signal processing in separate threads
   - Non-blocking I/O operations
   - Efficient memory management

2. RELIABILITY REQUIREMENTS:
   - False positive rate <5%
   - False negative rate <10%
   - Graceful degradation during signal loss
   - Automatic recovery from errors

3. USER EXPERIENCE:
   - Intuitive gesture learning curve
   - Clear feedback for all actions
   - Minimal setup requirements
   - Consistent performance across sessions

4. SECURITY & PRIVACY:
   - Local processing only (no cloud data)
   - Secure Spotify token storage
   - Optional anonymized usage analytics
   - User consent for data collection

==================================================
IMPLEMENTATION NOTES
==================================================

- Start with MVP focusing on double-blink → play/pause
- Iteratively add complexity (jaw clench, mental states)
- Extensive testing with multiple users for threshold tuning
- Consider machine learning for improved gesture recognition
- Plan for future features (playlist navigation, genre switching)
- Document all signal processing parameters for reproducibility

==================================================
SUCCESS METRICS
==================================================

- Gesture recognition accuracy >90%
- System response time <200ms
- User satisfaction score >4/5
- Successful Spotify integration >95% uptime
- False positive rate <5%
- Session duration capability >30 minutes continuous use
